<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Basic Meta Tags -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- SEO Meta Tags -->
  <meta name="description" content="Comprehensive AGI Risk Analysis">
  <meta name="keywords" content="agi, risk, convergence">
  <meta name="author" content="Forrest Landry">
  <meta name="robots" content="index, follow">

  <!-- Favicon -->
  <link rel="icon" href="https://github.githubassets.com/favicons/favicon-dark.png" type="image/png">
  <link rel="shortcut icon" href="https://github.githubassets.com/favicons/favicon-dark.png" type="image/png">

  <!-- Page Title (displayed on the browser tab) -->
  <title>Comprehensive AGI Risk Analysis</title>
</head>
<body>
  <p>
  TITL:
     <b>New Technology</b>
     by Forrest Landry
     April 29th, 2020.
  </p>
  <p>
  ABST:
     - where considering some of the issues
     associated with the introduction of
     any new technology,
     AGI/APS included.
  </p>
  <p>
  TEXT:
  </p>
  <p>
     > - ?; what are the social implications
     > of introducing a new technology,
     > like artificial intelligence,
     > into a community?.
  </p>
  <p>
     - that the use of X technology
       (and the rate of technology deployment,
       of all kinds, in general)
     is growing at a (historically/biologically) unprecedented rate.
       - as roughly parallel to the deployment of
       various kinds of new materials, metals,
       chemicals, pesticides, plastics,
       into the overall life systems environment.
         - ie as affecting all of, over time, plants, animals, humans,
           (and insects, birds, fish, microbes, etc, etc),
         and their long term cycles, inter-dependencies, evolution, etc.
  </p>
  <p>
     - that there will always be a claim in the form
     "that X technologies/materials
     have many widely beneficial applications".
       - that this claim, in itself, while potentially true,
       does not (cannot) tell the whole story
       of what actually matters,
       when making long term cultural choices.
       - that such claim is nearly always,
       directly or indirectly (naively) representing
       some/the business/developer interests.
         - as basically the interests of one or more individuals
         wanting to make money (Sell someone something),
         and are thus always setup to be culturally biased
         in favor of retaining/keeping/using the new technology.
  </p>
  <p>
       - that it is near completely inevitable
       that some tech developer or advocacy group
       will form, somewhere,
       that advocates the use of the new tech,
       and promotes its many benefits,
       advertises the advantages and novelty,
       showcases and celebrates practical applications
       and the problems solved, etc.
         - as loudly declare 'benefits',
         and maybe, if pressed, mention 'costs',
         but never, ever, mention any <b>risks</b>.
  </p>
  <p>
       - that the effectiveness of 'advocacy for' groups,
       will in general, typically, be more efficient
       than the 'protest against' groups.
         - that 'advocacy for' groups will tend to be better funded,
         (as paid for by commercial interests,
         as an investment in favor of the profits
         associated with the possible future commercial development
         of the sale of deployed material/process/technology X),
         than any possible comparable 'protest against' groups
         (which classically/generally categorically do not represent
         any specific commercial benefit,
         and therefore are not going to get an investment).
           - that even existing incumbent technology/business interests
           will not be able to invest much into
           'new tech disruptive' 'protest against' groups,
           insofar as they have usually already (by that stage)
           maximized economic extractiveness,
           and therefore, do not have much investment capital
           to provide for existing market protections,
           as indirectly implemented via the protest group.
  </p>
  <p>
     - where given various forms of:.
       - optimism bias.
       - action bias.
       - commercialization social bias.
       asymmetric advantage.
       Metcalfe's Law observations, etc;.
         - cite; (@ Wikipedia https://en.wikipedia.org/wiki/Metcalfe%27s_law).
     - ^; that it will always be the case
     that less attention will be paid
       (on the part of any party/actor)
     to the ways in which 'X technology':.
       - can be used maliciously;.
       - can cause harm
         (to self long term,
         to others,
         to the commons,
         environment, etc);.
       - and/increases risk of such harm,
       consequences and hazards of existing harms, etc.
  </p>
  <p>
  :
     - where given a conservative precautionary principle;.
     - that it is necessary to consider,
     in advance, as best as possible,
     all potential and identifiable (classes of) security threats,
     personal and social harms, risks, costs,
     systemic inequality, etc,
     from malicious uses of
     the new X technologies, methods, etc.
  </p>
  <p>
     - where on the part of the human species, taken as a whole;.
     - that there is a categorical need
     to identify better models and ways to better identify,
     forecast, prevent, and mitigate
     these harms, concerns, costs, threats, etc,
     associated with <b>any</b> novel material/process/technology.
  </p>
  <p>
     - where considering the question of
     what the long-term equilibrium
     between attackers and defenders will be;.
     - that it is clear that the equilibrium
     will shift to favor the attackers
     in proportion to the degree
     that the new tech/process/material
     provides any significant degree of asymmetric advantage,
     and/or takes advantage of
     inherent and/or non-mitigable disadvantages
     of the defenders.
       - as particularly the case where the costs/benefits
       associated with the new technology/process/material,
       tend to mostly/asymmetrically/locally accrue
       to the users/deployers/sellers,
       even if/when/where there are significant costs/risks/harms
       to the users future, to others, or to the environment
       are significant/extreme.
         - where given inevitable/inherent spending inefficiencies;
         that it is always better to borrow significantly against costs
         in the future, for local inequality benefits in the present,
         than it is to be conservative and hold/store value
         for the (even ones own) future.
  </p>
  <p>
     - where not considering a new technology,
     and where only considering a fight between two parties,
     each using the same range of tools/techniques/materials;.
     - and whereas the attacker must vanquish,
     and where the defender only need survive;.
     - and where given otherwise comparable overall strength,
     energy, skill, ability of investment, resources, capabilities, etc,
     of both attacker and defendant.
     - that most advantage goes to the defendant,
     absent significant surprise, 1st mover advantage,
     some significant compelling point of leverage, etc.
  </p>
  <p>
     - where (however) there is a significant advantage
     associated with a new process, tech, material, skill, resource, etc,
     that the attacker tends to have much more significant advantage,
     and thus is much more likely to overcome.
  </p>
  <p>
     - example; where AI and machine learning technology
     inherently has much higher complexity than any/most (all?)
     single humans (and most groups) can even begin to hope to muster,
     let along compensate for, identify and manage
     the complete range of consequences/risks/costs of, etc,
     then/that/therefore it is very much the case
     that the users of that new tech will (at least in the short term)
     seem to have significant advantages
     over those who elect not to use that tech.
       - as a kind of multi-polar trap.
  </p>
  <p>
  :
     - that the following is what <b>should</b> happen:.
  </p>
  <p>
       - 1; that Policymakers <b>should</b>
       collaborate closely with
       technical researchers
       so as to investigate, prevent, and mitigate potential
       malicious uses of the new tech, material, process, etc.
  </p>
  <p>
       - 2; that Researchers/engineers <b>should</b>
       take the dual-use nature
       of any new tech seriously,
       as allowing misuse-related considerations
       to influence research priorities and norms,
       and proactively engage the relevant actors/agencies,
       and ensure mitigation capabilities,
       when broad risk/cost/harmful applications/outcomes
       are foreseeable.
  </p>
  <p>
       - 3; that Best practices <b>should</b>
       be identified in research areas
       with more mature methods
       for addressing dual-use concerns,
       and such techniques should be imported and used
       where possible/applicable, and developed and verified
       to the point of consensus sufficiency in any case.
  </p>
  <p>
       - 4; that all parties/participants <b>should</b>
       actively seek to expand the range
       of stakeholders and domain experts
       involved in discussions/communication of these challenges,
       in terms of their sense-making procedures and methods,
       and moreover, to enable the adequate enablement
       of the agency of such conversational groups
       to implement whatever additional policies/procedures
       are consensus identified by such groups
       so as to balance the overall benefit/risk/harm/cost factors
       for all affected parties.
  </p>
  <p>
     - that there is significant skepticism
     that any of these things will actually happen,
     given that there are 'three disabling factors':.
  </p>
  <p>
       - 1; such actions are socially, procedurally, and economically
       very costly,
       and it is unlikely
       that any more investment into these aspects/actions
       will be taken
       than that minimally necessary
       to create the impression/presentation
       that these things are being done.
         - ?; who will pay the cost for such things?.
         - where/even if someone or some group
         were to be made to pay these costs;
         that it is much cheaper/easier
         to <b>simulate</b> doing these things,
         then it is to actually do these things;.
         - where regardless of appearances to the contrary;.
         - that/therefore; that it (usually) cannot be trusted;
         when necessary to rely on such things working;
         that the necessary safety benefits of these actions
         will actually accrue (to those who need them most).
  </p>
  <p>
       - 2; that the governance methods, techniques, infrastructure,
       and social norms necessary to implement
       effective sense making
       are basically, wholly, and completely absent
       for any group of humans
       larger than about one Dunbar number (150 persons).
         - that this is a historical artifact;
         that requires immediate mitigation;
         so as to deal with the increasing number of x-risk factors
         of multiple types, and their interactions,
         difficulty of mitigation,
         as depending on timeliness, etc.
  </p>
  <p>
       - 3; even/where some groups,
       individuals (researchers, engineers, etc)
       manage to implement effective sense making;
       that such collaborators tend to be
       largely disadvantaged/dis-empowered,
       when considered relative to the wealth and power
       of the actual decision makers (investors).
         - that the actual decision makers (the investors)
         will tend to be in favor of:.
           - shareholder value.
           - potential executive profits.
           - the business interests served
           by that new tech/method/process, etc.
  </p>
  <p>
         - that the people who know the most (at the face)
         tend to be the poorest people,
         while the people who have the most power, influence, resources,
         etc to effect change, are also the most remote
           (out of sight in a private gated mansion somewhere),
         and tend to have the least understanding
         of the actual balance of present and immediate future benefits
           (to themselves)
         and costs/risks/harms to others
           (the commons, environment, etc).
  </p>
  <p>
  :
     - where/without the design and adoption and implementation
     of wide-scale social changes
     in the means/methods of
     global system governance and economics process,
     infrastructure, means and objectives,
     such that those new systems of 'world scale'
     human/group choice making,
     are actually effective and adequate
     to the task of handling
     such situations/aspects/concerns/risks, etc;
     that eventual release of an 'unsolvable problem'
     will cause inexorable cultural and civilization collapse.
     - as needed to correct and compensate the three 'disabling factors';.
     - that new large scale governance/economic
       (group sense making,
       group choice making,
       and group agency enablement/execution)
     are all needed,
     in a particularly and robustly anti-corruptable manner.
     - where with anything short of new and fully effective/efficient
     group choice making process
       (as a proxy for fractal scalable
       macro-governance and macro-economics),
     as appropriately enabled and resourced
     and well and truly bound to act
     in the whole and complete interests
     of the whole ecosystem
       (ie, where as fully resolving
       of the principle agent problem),
     that no chance exists of resolving
     multi-polar trap issues
     and/or/therefore any class of
     long term chronic/systemic problems/risks/costs.
  </p>
</body>
</html>