TITL:
   *New Technology*
   by Forrest Landry
   April 29th, 2020.

ABST:
   - where considering some of the issues
   associated with the introduction of
   any new technology,
   AGI/APS included.

TEXT:

   > - ?; what are the social implications
   > of introducing a new technology,
   > like artificial intelligence,
   > into a community?.

   - that the use of X technology
     (and the rate of technology deployment,
     of all kinds, in general)
   is growing at a (historically/biologically) unprecedented rate.
     - as roughly parallel to the deployment of
     various kinds of new materials, metals,
     chemicals, pesticides, plastics,
     into the overall life systems environment.
       - ie as affecting all of, over time, plants, animals, humans,
         (and insects, birds, fish, microbes, etc, etc),
       and their long term cycles, inter-dependencies, evolution, etc.

   - that there will always be a claim in the form
   "that X technologies/materials
   have many widely beneficial applications".
     - that this claim, in itself, while potentially true,
     does not (cannot) tell the whole story
     of what actually matters,
     when making long term cultural choices.
     - that such claim is nearly always,
     directly or indirectly (naively) representing
     some/the business/developer interests.
       - as basically the interests of one or more individuals
       wanting to make money (Sell someone something),
       and are thus always setup to be culturally biased
       in favor of retaining/keeping/using the new technology.

     - that it is near completely inevitable
     that some tech developer or advocacy group
     will form, somewhere,
     that advocates the use of the new tech,
     and promotes its many benefits,
     advertises the advantages and novelty,
     showcases and celebrates practical applications
     and the problems solved, etc.
       - as loudly declare 'benefits',
       and maybe, if pressed, mention 'costs',
       but never, ever, mention any *risks*.

     - that the effectiveness of 'advocacy for' groups,
     will in general, typically, be more efficient
     than the 'protest against' groups.
       - that 'advocacy for' groups will tend to be better funded,
       (as paid for by commercial interests,
       as an investment in favor of the profits
       associated with the possible future commercial development
       of the sale of deployed material/process/technology X),
       than any possible comparable 'protest against' groups
       (which classically/generally categorically do not represent
       any specific commercial benefit,
       and therefore are not going to get an investment).
         - that even existing incumbent technology/business interests
         will not be able to invest much into
         'new tech disruptive' 'protest against' groups,
         insofar as they have usually already (by that stage)
         maximized economic extractiveness,
         and therefore, do not have much investment capital
         to provide for existing market protections,
         as indirectly implemented via the protest group.

   - where given various forms of:.
     - optimism bias.
     - action bias.
     - commercialization social bias.
     asymmetric advantage.
     Metcalfe's Law observations, etc;.
       - cite; (@ Wikipedia https://en.wikipedia.org/wiki/Metcalfe%27s_law).
   - ^; that it will always be the case
   that less attention will be paid
     (on the part of any party/actor)
   to the ways in which 'X technology':.
     - can be used maliciously;.
     - can cause harm
       (to self long term,
       to others,
       to the commons,
       environment, etc);.
     - and/increases risk of such harm,
     consequences and hazards of existing harms, etc.

:
   - where given a conservative precautionary principle;.
   - that it is necessary to consider,
   in advance, as best as possible,
   all potential and identifiable (classes of) security threats,
   personal and social harms, risks, costs,
   systemic inequality, etc,
   from malicious uses of
   the new X technologies, methods, etc.

   - where on the part of the human species, taken as a whole;.
   - that there is a categorical need
   to identify better models and ways to better identify,
   forecast, prevent, and mitigate
   these harms, concerns, costs, threats, etc,
   associated with *any* novel material/process/technology.

   - where considering the question of
   what the long-term equilibrium
   between attackers and defenders will be;.
   - that it is clear that the equilibrium
   will shift to favor the attackers
   in proportion to the degree
   that the new tech/process/material
   provides any significant degree of asymmetric advantage,
   and/or takes advantage of
   inherent and/or non-mitigable disadvantages
   of the defenders.
     - as particularly the case where the costs/benefits
     associated with the new technology/process/material,
     tend to mostly/asymmetrically/locally accrue
     to the users/deployers/sellers,
     even if/when/where there are significant costs/risks/harms
     to the users future, to others, or to the environment
     are significant/extreme.
       - where given inevitable/inherent spending inefficiencies;
       that it is always better to borrow significantly against costs
       in the future, for local inequality benefits in the present,
       than it is to be conservative and hold/store value
       for the (even ones own) future.

   - where not considering a new technology,
   and where only considering a fight between two parties,
   each using the same range of tools/techniques/materials;.
   - and whereas the attacker must vanquish,
   and where the defender only need survive;.
   - and where given otherwise comparable overall strength,
   energy, skill, ability of investment, resources, capabilities, etc,
   of both attacker and defendant.
   - that most advantage goes to the defendant,
   absent significant surprise, 1st mover advantage,
   some significant compelling point of leverage, etc.

   - where (however) there is a significant advantage
   associated with a new process, tech, material, skill, resource, etc,
   that the attacker tends to have much more significant advantage,
   and thus is much more likely to overcome.

   - example; where AI and machine learning technology
   inherently has much higher complexity than any/most (all?)
   single humans (and most groups) can even begin to hope to muster,
   let along compensate for, identify and manage
   the complete range of consequences/risks/costs of, etc,
   then/that/therefore it is very much the case
   that the users of that new tech will (at least in the short term)
   seem to have significant advantages
   over those who elect not to use that tech.
     - as a kind of multi-polar trap.

:
   - that the following is what *should* happen:.

     - 1; that Policymakers *should*
     collaborate closely with
     technical researchers
     so as to investigate, prevent, and mitigate potential
     malicious uses of the new tech, material, process, etc.

     - 2; that Researchers/engineers *should*
     take the dual-use nature
     of any new tech seriously,
     as allowing misuse-related considerations
     to influence research priorities and norms,
     and proactively engage the relevant actors/agencies,
     and ensure mitigation capabilities,
     when broad risk/cost/harmful applications/outcomes
     are foreseeable.

     - 3; that Best practices *should*
     be identified in research areas
     with more mature methods
     for addressing dual-use concerns,
     and such techniques should be imported and used
     where possible/applicable, and developed and verified
     to the point of consensus sufficiency in any case.

     - 4; that all parties/participants *should*
     actively seek to expand the range
     of stakeholders and domain experts
     involved in discussions/communication of these challenges,
     in terms of their sense-making procedures and methods,
     and moreover, to enable the adequate enablement
     of the agency of such conversational groups
     to implement whatever additional policies/procedures
     are consensus identified by such groups
     so as to balance the overall benefit/risk/harm/cost factors
     for all affected parties.

   - that there is significant skepticism
   that any of these things will actually happen,
   given that there are 'three disabling factors':.

     - 1; such actions are socially, procedurally, and economically
     very costly,
     and it is unlikely
     that any more investment into these aspects/actions
     will be taken
     than that minimally necessary
     to create the impression/presentation
     that these things are being done.
       - ?; who will pay the cost for such things?.
       - where/even if someone or some group
       were to be made to pay these costs;
       that it is much cheaper/easier
       to *simulate* doing these things,
       then it is to actually do these things;.
       - where regardless of appearances to the contrary;.
       - that/therefore; that it (usually) cannot be trusted;
       when necessary to rely on such things working;
       that the necessary safety benefits of these actions
       will actually accrue (to those who need them most).

     - 2; that the governance methods, techniques, infrastructure,
     and social norms necessary to implement
     effective sense making
     are basically, wholly, and completely absent
     for any group of humans
     larger than about one Dunbar number (150 persons).
       - that this is a historical artifact;
       that requires immediate mitigation;
       so as to deal with the increasing number of x-risk factors
       of multiple types, and their interactions,
       difficulty of mitigation,
       as depending on timeliness, etc.

     - 3; even/where some groups,
     individuals (researchers, engineers, etc)
     manage to implement effective sense making;
     that such collaborators tend to be
     largely disadvantaged/dis-empowered,
     when considered relative to the wealth and power
     of the actual decision makers (investors).
       - that the actual decision makers (the investors)
       will tend to be in favor of:.
         - shareholder value.
         - potential executive profits.
         - the business interests served
         by that new tech/method/process, etc.

       - that the people who know the most (at the face)
       tend to be the poorest people,
       while the people who have the most power, influence, resources,
       etc to effect change, are also the most remote
         (out of sight in a private gated mansion somewhere),
       and tend to have the least understanding
       of the actual balance of present and immediate future benefits
         (to themselves)
       and costs/risks/harms to others
         (the commons, environment, etc).

:
   - where/without the design and adoption and implementation
   of wide-scale social changes
   in the means/methods of
   global system governance and economics process,
   infrastructure, means and objectives,
   such that those new systems of 'world scale'
   human/group choice making,
   are actually effective and adequate
   to the task of handling
   such situations/aspects/concerns/risks, etc;
   that eventual release of an 'unsolvable problem'
   will cause inexorable cultural and civilization collapse.
   - as needed to correct and compensate the three 'disabling factors';.
   - that new large scale governance/economic
     (group sense making,
     group choice making,
     and group agency enablement/execution)
   are all needed,
   in a particularly and robustly anti-corruptable manner.
   - where with anything short of new and fully effective/efficient
   group choice making process
     (as a proxy for fractal scalable
     macro-governance and macro-economics),
   as appropriately enabled and resourced
   and well and truly bound to act
   in the whole and complete interests
   of the whole ecosystem
     (ie, where as fully resolving
     of the principle agent problem),
   that no chance exists of resolving
   multi-polar trap issues
   and/or/therefore any class of
   long term chronic/systemic problems/risks/costs.
